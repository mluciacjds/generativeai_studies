{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e7e094-b239-4bd6-92ca-ff57afac6ced",
   "metadata": {},
   "source": [
    "\n",
    "Class torch.nn.Module [SOURCE]\n",
    "bASE CLASS FOR ALL NEURAL NETWORK MODULES.\n",
    "YOUR MODELS SHOULD ALSO SUBCLASS THIS CLASS\n",
    "MODULES CAN ALSO CONTAIN OTHER MODULES, ALLOWING TO NEST THEM IN  A TREE STRUCTURE. \n",
    "YOU CAN ASSIGN THE SUBMODULES AS REGULAR ATTRIBUTES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5208926a-fae6-4b54-bff6-a737949db626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.6.3)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deec5460-1e42-48da-a416-ec9f6e9a9f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.6.3)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "Installing collected packages: tokenizers, safetensors, xxhash, tqdm, packaging, huggingface-hub, transformers, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "sagemaker 2.165.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 6.6.0 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.18.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.13.1 huggingface-hub-0.15.1 packaging-23.1 safetensors-0.3.1 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.30.2 xxhash-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288a8e5b-90b0-4610-af41-ea4e74976aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a43b1b-e4a9-40c5-91b4-342dcf89f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,20,5)\n",
    "        self.conv2 = nn.Conv2d(20,20,5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2567fbca-5af9-45d3-b6f4-05254337968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_k, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        # this is for implementing the following formula\n",
    "        # Attention(Q,K,V)  = softmax((QK^T)/sqrt(dk))V \n",
    "        self.key = nn.Linear(d_model, d_k*n_heads)\n",
    "        self.query = nn.Linear(d_model, d_k*n_heads)\n",
    "        self.value = nn.Linear(d_model, d_k*n_heads)\n",
    "        \n",
    "        #final linear layer\n",
    "        self.fc = nn.Linear(d_k*n_heads, d_model)\n",
    "    \n",
    "    def forward(self, q,k,v, mask =None):\n",
    "        \n",
    "        q = self.query(q) # NxT x (hd_k)\n",
    "        k = self.key(k) # N x T x (hd_k)\n",
    "        v = self.value(v) # N x T x (hd_v)\n",
    "        \n",
    "        N = q.shape[0]\n",
    "        T = q.shape[1]\n",
    "        \n",
    "        q = q.view(N,T,self.n_heads, self.d_k).transpose(1,2)\n",
    "        k = k.view(N,T,self.n_heads, self.d_k).transpose(1,2)\n",
    "        v = v.view(N,T,self.n_heads, self.d_k).transpose(1,2)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        # (N,h,T,d_k) X (N,h,d_k,T) --> (N,h,T,T)\n",
    "        # in transpose switch dimension 2 and 1, \n",
    "        \"\"\"\n",
    "        # Its like doing this:\n",
    "        for n in range(N):\n",
    "            for head, in range(h):\n",
    "                score[n,head] = q[n,head]@ k[n,head].T\n",
    "                # (T, d_k) X (d_k,T) -> (T,T)\n",
    "        \"\"\"\n",
    "        \n",
    "        attn_scores = q @ k.transpose(-2,-1) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if (not mask is None):\n",
    "            #(N,T) -> (N,1,1,T)\n",
    "            #for correct broadcasting, it applies the mask in the aprropriate places\n",
    "            # wherever the first argument is true apply the value of the second argument, \n",
    "            # in this case, infinity(for softmax purposes)\n",
    "            attn_scores = attn_scores.masked_fill(\n",
    "                mask[:, None, None, :] == 0, float('-inf'))\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # compute attention-weighted values\n",
    "        # (N,h,T, T) X (N, h, T, d_k) -->  (N, h, , T, d_k)\n",
    "        \n",
    "        A = attn_weights @ v\n",
    "\n",
    "        A = A.transpose(1,2) # (N,T,h,d_k)\n",
    "        A = A.contiguous().view(N, T, self.d_k*self.n_heads) # (N,T,h*d_k)\n",
    "        \n",
    "        return self.fc(A)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b176f4b-bd1d-4d61-a5c5-16cf21fdb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_k, d_model, n_heads, dropout_prob =0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mha = MultiHeadAttention(d_k, d_model, n_heads)\n",
    "        self.ann = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model*4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.Dropout(dropout_prob))\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Passing x as query, key and value , thats why 3 x\n",
    "        \n",
    "        x = self.ln1(x + self.mha(x, x, x, mask))\n",
    "        x = self.ln2(x + self.ann(x))\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ce447c-09cd-484e-a9ab-80cb12c196ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model, max_len =2048, dropout_prob = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        exp_term = torch.arange(0,d_model,2)\n",
    "        div_term = torch.exp(exp_term * (-math.log(1000.0)/d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position*div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape: NxTxD\n",
    "        x= x+ self.pe[:,:x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b29ae6f5-daf0-4ed2-9166-bf0965ac1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                  vocab_size,\n",
    "                  max_len,\n",
    "                  d_k,\n",
    "                  d_model,\n",
    "                  n_heads,\n",
    "                  n_layers,\n",
    "                  n_classes,\n",
    "                  dropout_prob):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        transformer_blocks =[\n",
    "            TransformerBlock(\n",
    "            d_k,\n",
    "            d_model,\n",
    "            n_heads,\n",
    "            dropout_prob) for _ in range(n_layers)]\n",
    "        self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(d_model, n_classes)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for block in self.transformer_blocks:\n",
    "            x=block(x,mask)\n",
    "            \n",
    "        # many-to-one (x has the shape N x T x D)\n",
    "        x = x[:,0,:]    \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6dc899-81f6-48b7-a1ea-b52c6dada086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Encoder(20_000, 1024,16,64,4,2,5,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ef2c6d-96fb-4b23-bc19-54afb597c6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(20000, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2afd444b-e9a1-4a2a-bca6-1f9f614525c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.random.randint(0,20_000, size = (8,512))\n",
    "x_t = torch.tensor(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60e145f-d397-42d6-a56c-8b2a966652be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = np.ones((8,512))\n",
    "mask[:,256:]=0\n",
    "mask_t = torch.tensor(mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "797c50b4-6b55-4ae5-8b94-b10d47014880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = model(x_t,mask_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c672c8d-9c4d-4a73-b7b6-c9cf17d1250e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "307249d3-aaeb-46f2-95f5-97e3695b1fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.13.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d496c847-5373-4d69-b01b-49839bb4990f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bab9f11-1a39-4067-9a48-ee587030c224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased' # does not use segment embeddings - sentences separated by special tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436bda9e-6174-4d6b-9354-f0be689be969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff7fee24-5f69-4f50-aa81-fdbef34219c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65772f23b6a4b2b86ce5ed99c791e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"sst2\") #dataset for sentiment analysis glue benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25a533ab-069c-402a-b25b-232227f76f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ab04bef-92c4-4b4c-9595-4dfa30d7c6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b20c4584-8184-4437-88b4-55d0da95b618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-260390e2989cde42.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-05d706196ce03b81.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb38f32e-54af-41f1-8eeb-13813115b50c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbde480f-3895-4217-8288-ccf1379eb40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets\n",
    "#attention mask indicates wich tokens are real tokens and not padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3765a363-ba74-41f5-a66f-1cc56e74fc24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\",\"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2e023d-313c-4451-8bf1-8de559ba4788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8066e43-6053-4f6e-90ff-3ac2f3fa3b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71fe3b69-4118-4d4b-9fac-1d724deeb4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle = True,\n",
    "    batch_size=32,\n",
    "    collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3692203-fd27-4c54-b274-da3fdac995b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=32,\n",
    "    collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0162d155-d5e5-4a51-ae52-e17973144dee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: labels v.shape: torch.Size([32])\n",
      "k: input_ids v.shape: torch.Size([32, 46])\n",
      "k: attention_mask v.shape: torch.Size([32, 46])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    for k,v in batch.items():\n",
    "        print(\"k:\",k, \"v.shape:\", v.shape)\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd33b1d8-a0dc-4b23-8786-055bd5f5611c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set (tokenized_datasets['train']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83bc05f4-db01-467a-93c8-4c033ff7d79a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fd0f88c-ac1e-418a-9f91-936395d628a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distilbert-base-uncased': 512,\n",
       " 'distilbert-base-uncased-distilled-squad': 512,\n",
       " 'distilbert-base-cased': 512,\n",
       " 'distilbert-base-cased-distilled-squad': 512,\n",
       " 'distilbert-base-german-cased': 512,\n",
       " 'distilbert-base-multilingual-cased': 512}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d86ea464-5fb7-403f-a854-f46dc1548288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Encoder(\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    max_len = tokenizer.max_model_input_sizes[checkpoint],\n",
    "    d_k = 16,\n",
    "    d_model = 64,\n",
    "    n_heads = 4,\n",
    "    n_layers = 2,\n",
    "    n_classes = 2,\n",
    "    dropout_prob = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b13a07b-386c-4f84-ae29-9024669e02c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(28996, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a020e5a-9c51-4184-9a8d-d88eeddaee38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccb5ed56-f327-4522-b268-352eddd3c9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b15978df-ee09-4ac7-bbfc-8dab4811bf82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, valid_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    \n",
    "    for it in range(epochs):\n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = 0\n",
    "        n_train = 0\n",
    "        for batch in train_loader:\n",
    "            #move data to gpu\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass\n",
    "            outputs = model (batch['input_ids'], batch['attention_mask'])\n",
    "            loss = criterion(outputs, batch['labels'])\n",
    "            \n",
    "            #Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # loss is the average crosentropy over the batch\n",
    "            # multiply the loss with the full batch size in order to posteriorly take de average loss for the whole train set\n",
    "            train_loss += loss.item()*batch['input_ids'].size(0)\n",
    "            n_train += batch['input_ids'].size(0)\n",
    "            \n",
    "        #Get average train loss\n",
    "        train_loss = train_loss/n_train\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        n_test = 0\n",
    "        \n",
    "        for batch in valid_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model (batch['input_ids'], batch['attention_mask'])\n",
    "            loss = criterion(outputs, batch['labels'])\n",
    "            test_loss += loss.item()*batch['input_ids'].size(0)\n",
    "            n_test += batch['input_ids'].size(0)\n",
    "        test_loss = test_loss/n_test\n",
    "        \n",
    "        # Save losses\n",
    "        \n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] =  test_loss\n",
    "        \n",
    "        dt = datetime.now() - t0\n",
    "        print (f'Epoch {it+1}/{epochs}, Train Loss: {train_loss: .4f},\\\n",
    "        Test Loss {test_loss:.4f}, Duration {dt}')\n",
    "    return train_losses, test_losses\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ead645d4-c6ae-49a8-8371-6aae4a9b639c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Train Loss:  0.2996,        Test Loss 0.5081, Duration 0:00:20.324413\n",
      "Epoch 2/4, Train Loss:  0.2616,        Test Loss 0.6129, Duration 0:00:20.271290\n",
      "Epoch 3/4, Train Loss:  0.2294,        Test Loss 0.5449, Duration 0:00:20.344591\n",
      "Epoch 4/4, Train Loss:  0.2092,        Test Loss 0.5513, Duration 0:00:20.281684\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = train(\n",
    "    model, criterion, optimizer, train_loader, valid_loader, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19c20bf0-a1c1-461d-8b3d-d3ad68011a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.9425, Test acc:  0.7844\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "model.eval()\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "for batch in train_loader:\n",
    "    # Move to GPU\n",
    "    batch = {k: v.to(device) for k,v in batch.items()}\n",
    "    \n",
    "    #Forward pass\n",
    "    outputs  = model (batch['input_ids'], batch['attention_mask'])\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    \n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    \n",
    "    #update counts\n",
    "    n_correct += (predictions == batch['labels']).sum().item()\n",
    "    n_total += batch['labels'].shape[0]\n",
    "    \n",
    "train_acc = n_correct /n_total\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "for batch in valid_loader:\n",
    "    \n",
    "    # Move to GPU\n",
    "    batch = {k: v.to(device) for k,v in batch.items()}\n",
    "    \n",
    "    #Forward pass\n",
    "    outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "    \n",
    "    # Get Prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    \n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    \n",
    "    #update counts\n",
    "    n_correct += (predictions == batch['labels']).sum().item()\n",
    "    n_total += batch['labels'].shape[0]\n",
    "    \n",
    "test_acc = n_correct /n_total\n",
    "print(f'Train acc: {train_acc: .4f}, Test acc: {test_acc: .4f}') \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5a437-a696-491f-a085-79fde4dc8f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
