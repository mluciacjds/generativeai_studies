{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6a0571-868d-4214-a2e8-77e651855f27",
   "metadata": {},
   "source": [
    "# Task: Models and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b7e51a-4272-4bc2-9fa5-31ec912325b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.6.3)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b4a89f-3a44-4e7f-bc79-51150544149f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Using cached torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6600ad4b-fea9-4579-b41c-a2a1eec5156b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.6.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, packaging, huggingface-hub, transformers\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "sagemaker 2.165.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 6.6.0 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.18.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.15.1 packaging-23.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf26b04-dd51-4df2-ac40-776f5a0ca84e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (6.6.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /opt/conda/lib/python3.7/site-packages (from transformers[torch]) (1.13.1)\n",
      "Collecting accelerate>=0.20.2 (from transformers[torch])\n",
      "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.20.2->transformers[torch]) (5.6.7)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (65.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (0.40.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[torch]) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[torch]) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[torch]) (2023.5.7)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896acce9-13e3-4df7-9328-a76b4f9e97f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.31.0)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (6.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.6.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "Installing collected packages: xxhash, tqdm, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "Successfully installed datasets-2.13.1 tqdm-4.65.0 xxhash-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a972794-ad07-4899-b8ca-45caeef8019b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb73ed8-facc-48f5-98a8-85ce97dc0ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c727054-0f64-4452-835d-f24dccf7d5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba34030-f60d-4d7f-ad4b-0daafe349797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2088, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd3a0e0-1527-435a-b40a-5f63d64e3bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"hello world\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053cb58e-c46b-45e3-9524-207e7866f31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e80354-116c-40e0-8df9-a36f4a01796e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7592, 2088]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe773cf-7f43-4280-872b-fb558bd45491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e6c931-6ce4-4a3d-8c0c-c9ca593c4d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9716d985-f521-454a-bcb4-11762b67074e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2088, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e27e31-80db-4202-92e3-b878de33550a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'hello', 'world', '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tokenizer.convert_ids_to_tokens([101, 7592, 2088, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d97788-9f8a-46b5-9f74-6e79dee985c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello world [SEP]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 7592, 2088, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd957b0e-d536-4a24-9719-9fbcc84a1064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2088, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer(\"hello world\")\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377b710e-f0a2-450c-a95a-8065d74839ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2088,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer(\"hello world\", return_tensors = 'pt')\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2e89d15-2145-4f35-88d7-078a8240e79e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2066, 8870, 1012, 102], [101, 2079, 2017, 2066, 8870, 2205, 1029, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"I like cats.\", \"Do you like cats too?\"]\n",
    "tokenizer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baaa9b30-1eb3-40e0-bde4-f0a258cff77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef16c436-aefb-48e9-9931-183ba20afe6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ec1cac-caf7-4651-a952-6f30ada67ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "072b86e3-929d-401e-97bb-3e1c073915fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.1908, 0.1490]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0263db6e-3f70-40ce-9c62-eb8e914fb29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4660350-9568-4e3a-8d43-d8ae116e1568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(**model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48abc083-1913-4dd5-92af-7a939ea9f73b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0482,  0.4658, -0.3533]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f96734d3-8314-42b0-85b4-aa5425462d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0482,  0.4658, -0.3533]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de426bdc-89a9-44b0-adc3-a9f5ca77de78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0482,  0.4658, -0.3533]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e83d52cd-8028-469a-a076-ec09380c9b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0482,  0.4658, -0.3533]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67810009-f89c-4e71-9cf5-0b241935315d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04821119,  0.4657584 , -0.3532558 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecba1cfb-ab34-44c0-a2ca-f68f458622b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2066, 8870, 1012,  102,    0,    0],\n",
       "        [ 101, 2079, 2017, 2066, 8870, 2205, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"I like cats.\", \"Do you like cats too?\"]\n",
    "model_inputs = tokenizer(data, padding = True, truncation = True, return_tensors ='pt')\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83378008-14fe-4060-911c-2a2e80e1c8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.1302,  0.6250, -0.4188],\n",
       "        [ 0.1254,  0.6582, -0.4015]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model (**model_inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347f671-2414-481c-a6a0-1a5cd927a267",
   "metadata": {},
   "source": [
    "# Task 1: Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0a0d82-c560-4a68-81f2-8a0132c0449a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020cd1ac-410c-4b98-ac87-8b9e0433b9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d596774e-5e93-4208-82d0-ce42cfd35453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b59505f-5c9d-40ef-b34d-18bf992501ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd071bf3b82b459a812dfb7d3797c114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b0e4d3-197f-48a5-ab0a-03c8dd984813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f83c1229-dc49-4c32-a4ae-017731e20230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'idx'],\n",
       "    num_rows: 67349\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c60041-9ed0-4283-bc93-6c37080e6f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_DATASET_REFS',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_local_temp_path',\n",
       " '_check_index_is_initialized',\n",
       " '_data',\n",
       " '_estimate_nbytes',\n",
       " '_fingerprint',\n",
       " '_format_columns',\n",
       " '_format_kwargs',\n",
       " '_format_type',\n",
       " '_generate_tables_from_cache_file',\n",
       " '_generate_tables_from_shards',\n",
       " '_get_cache_file_path',\n",
       " '_get_output_signature',\n",
       " '_getitem',\n",
       " '_indexes',\n",
       " '_indices',\n",
       " '_info',\n",
       " '_map_single',\n",
       " '_new_dataset_with_indices',\n",
       " '_output_all_columns',\n",
       " '_push_parquet_shards_to_hub',\n",
       " '_save_to_disk_single',\n",
       " '_select_contiguous',\n",
       " '_select_with_indices_mapping',\n",
       " '_split',\n",
       " 'add_column',\n",
       " 'add_elasticsearch_index',\n",
       " 'add_faiss_index',\n",
       " 'add_faiss_index_from_external_arrays',\n",
       " 'add_item',\n",
       " 'align_labels_with_mapping',\n",
       " 'builder_name',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'citation',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'column_names',\n",
       " 'config_name',\n",
       " 'data',\n",
       " 'dataset_size',\n",
       " 'description',\n",
       " 'download_checksums',\n",
       " 'download_size',\n",
       " 'drop_index',\n",
       " 'export',\n",
       " 'features',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'format',\n",
       " 'formatted_as',\n",
       " 'from_buffer',\n",
       " 'from_csv',\n",
       " 'from_dict',\n",
       " 'from_file',\n",
       " 'from_generator',\n",
       " 'from_json',\n",
       " 'from_list',\n",
       " 'from_pandas',\n",
       " 'from_parquet',\n",
       " 'from_spark',\n",
       " 'from_sql',\n",
       " 'from_text',\n",
       " 'get_index',\n",
       " 'get_nearest_examples',\n",
       " 'get_nearest_examples_batch',\n",
       " 'homepage',\n",
       " 'info',\n",
       " 'is_index_initialized',\n",
       " 'iter',\n",
       " 'license',\n",
       " 'list_indexes',\n",
       " 'load_elasticsearch_index',\n",
       " 'load_faiss_index',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'prepare_for_task',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'reset_format',\n",
       " 'save_faiss_index',\n",
       " 'save_to_disk',\n",
       " 'search',\n",
       " 'search_batch',\n",
       " 'select',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'shape',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'size_in_bytes',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'supervised_keys',\n",
       " 'task_templates',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_iterable_dataset',\n",
       " 'to_json',\n",
       " 'to_list',\n",
       " 'to_pandas',\n",
       " 'to_parquet',\n",
       " 'to_sql',\n",
       " 'to_tf_dataset',\n",
       " 'train_test_split',\n",
       " 'unique',\n",
       " 'version',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(raw_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e665f1cf-72f2-430b-be50-b81f734a69a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd925887-7179-40cf-be4a-b559a3048a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a427d30-adfa-462d-bdaf-d0c627506d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryMappedTable\n",
       "sentence: string\n",
       "label: int64\n",
       "idx: int32\n",
       "----\n",
       "sentence: [[\"hide new secretions from the parental units \",\"contains no wit , only labored gags \",\"that loves its characters and communicates something rather beautiful about human nature \",\"remains utterly satisfied to remain the same throughout \",\"on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \",...,\"you wish you were at home watching that movie instead of in the theater watching this one \",\"'s no point in extracting the bare bones of byatt 's plot for purposes of bland hollywood romance \",\"underdeveloped \",\"the jokes are flat \",\"a heartening tale of small victories \"],[\"suspense , intriguing characters and bizarre bank robberies , \",\"a gritty police thriller with all the dysfunctional family dynamics one could wish for \",\"with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life \",\"nonetheless appreciates the art and reveals a music scene that transcends culture and race . \",\"do we really need the tiger beat version ? \",...,\"when there 's nothing else happening \",\"on cable \",\"it with ring , \",\"far from a groundbreaking endeavor \",\"that these women are spectacular \"],...,[\"it does turn out to be a bit of a cheat in the end \",\"may be convinced that he has something significant to say \",\"to be both hugely entertaining and uplifting . \",\", boredom never takes hold . \",\"left to work with , sort of like michael jackson 's nose \",...,\"from a severe case of hollywood-itis \",\"the very best of them \",\"thrills , \",\"'s attracting audiences to unfaithful \",\"impressively delicate range \"],[\"starts off promisingly but then proceeds to flop \",\"distinguished actor \",\"on their parents ' anguish \",\"pays off and is effective if you stick with it \",\"is n't particularly funny \",...,\"a delightful comedy \",\"anguish , anger and frustration \",\"at achieving the modest , crowd-pleasing goals it sets for itself \",\"a patient viewer \",\"this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \"]]\n",
       "label: [[0,0,1,0,0,...,0,0,0,0,1],[1,1,1,1,0,...,0,0,1,0,1],...,[0,0,1,1,0,...,0,1,1,1,1],[0,1,0,1,0,...,1,0,1,1,0]]\n",
       "idx: [[0,1,2,3,4,...,995,996,997,998,999],[1000,1001,1002,1003,1004,...,1995,1996,1997,1998,1999],...,[66000,66001,66002,66003,66004,...,66995,66996,66997,66998,66999],[67000,67001,67002,67003,67004,...,67344,67345,67346,67347,67348]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcdc048b-f7a2-42af-9092-358caf851acc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fcc9e2a-5ad8-48b9-bcba-7ba821904ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad2005de-2f45-4591-998e-b3b8cd69e87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8640d46e-b6fd-4a6b-b614-650f2fb42567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " 'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102],\n",
      "               [101,\n",
      "                3397,\n",
      "                2053,\n",
      "                15966,\n",
      "                1010,\n",
      "                2069,\n",
      "                4450,\n",
      "                2098,\n",
      "                18201,\n",
      "                2015,\n",
      "                102],\n",
      "               [101,\n",
      "                2008,\n",
      "                7459,\n",
      "                2049,\n",
      "                3494,\n",
      "                1998,\n",
      "                10639,\n",
      "                2015,\n",
      "                2242,\n",
      "                2738,\n",
      "                3376,\n",
      "                2055,\n",
      "                2529,\n",
      "                3267,\n",
      "                102]]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = tokenizer(raw_datasets['train'][0:3]['sentence'])\n",
    "pprint(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2696d81f-8e36-4d3d-898b-293af2d5d71e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-e5bbe50e823fc735.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-48d2e088774b0ef9.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41860d50-e0ac-4e7c-ab31-9b7a1f08ade9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"my_trainer\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    num_train_epochs =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad9d48c8-7d6d-4525-8339-93b829c805b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ca27c13-e344-4aa4-b7eb-96f58e8b3583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcc75019-9ff4-47ae-91e5-70a34e851dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "DistilBertForSequenceClassification                     --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              23,440,896\n",
       "│    │    └─Embedding: 3-2                              393,216\n",
       "│    │    └─LayerNorm: 3-3                              1,536\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             42,527,232\n",
       "├─Linear: 1-2                                           590,592\n",
       "├─Linear: 1-3                                           1,538\n",
       "├─Dropout: 1-4                                          --\n",
       "================================================================================\n",
       "Total params: 66,955,010\n",
       "Trainable params: 66,955,010\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1143767-e57e-4b19-9bbf-bba2e4a40a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_before = []\n",
    "for name, p in model.named_parameters():\n",
    "    params_before.append(p.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca0ef3c1-fd54-47e4-9cfb-a8a8f78e7528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"glue\",\"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea6996b6-1616-4776-aacf-896b5255efdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels  = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis =-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8731354-3443-4983-8cba-f312dfe6ffb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fae2048c-8ab8-412b-a343-4273a2f2d283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='8419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   9/8419 00:08 < 2:47:02, 0.84 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         )\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2005\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step_was_skipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/accelerate/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_after\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mscale_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_switch_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;31m# Just adding the square of the weights to the loss function is *not*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c1ef21-4849-4693-8228-43768474b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"my_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9168294-b0b9-41b9-b463-1c5ab048d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb4714-2d1d-4e60-b7e6-2fb752899b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls my_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a9e61-afce-4536-aebf-4e0f9ed809fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245dd38c-a146-4613-bc42-6d515944066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = pipeline('text-classification', model = \"my_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca68b3-7a39-473e-b298-b4b2712e7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel(\"This movie is great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845237e-855a-465d-b787-70532b943936",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel(\"This movie sucks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f91804-8282-43ff-82f3-14eb1e016109",
   "metadata": {},
   "source": [
    "# Fine Tuning with Custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f186888c-0843-422d-b270-f7da434f7fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from torchinfo import summary\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d332d9-d836-4810-8fb5-3b63fe4e0351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('AirlineTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e75ea0ec-cd46-46c8-a55e-1af82ea4873c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4308b84e-fa96-470a-ad1c-cf670b66f193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df[['airline_sentiment', 'text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "239712f9-bd1a-4015-bade-db89a6fcf9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f85d9f-fe1a-469f-a190-b97db24bb25b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f246a61c890>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de1jVdYLH8Q8CHkABSRPEMGkqBgebStTACrcEyktaTU2JGLtFupJk5Fh0mdRUNscLE066NY5aajrPusza6AjorrcFTFHzuuq23maTIZNA1OAIv/3Dh996Qo2DIPb1/XqensfzO9/z5XvIL7z5/c4RD8uyLAEAABikTWsvAAAAoLkROAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwDoEDAACM49XaC2gpdXV1+uqrr+Tv7y8PD4/WXg4AAGgEy7J0+vRphYaGqk2bpp+HMTZwvvrqK4WFhbX2MgAAQBMcP35ct9xyS5Mfb2zg+Pv7S7rwCQoICGi2eZ1Op/Lz85WQkCBvb+9mmxdA47EPgdbVknuwsrJSYWFh9vfxpjI2cOovSwUEBDR74Pj5+SkgIIAvrEArYR8Creta7MGrfXkJLzIGAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxvFp7AQAA3Oi6v76qtZfgFoenpel9WnsVV8YZHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcdwKnPPnz+utt95SeHi4fH19ddttt2ny5Mmqq6uzx1iWpYkTJyo0NFS+vr7q37+/9u7d6zJPeXm5kpOTFRgYqMDAQCUnJ+vbb791GbN7927FxcXJ19dXXbt21eTJk2VZ1lU8VQAAcKNwK3Dee+89zZs3T3PmzNH+/fs1ffp0/eY3v1FOTo49Zvr06Zo1a5bmzJmjrVu3KiQkRPHx8Tp9+rQ9Zvjw4dq5c6fWrFmjNWvWaOfOnUpOTrbvr6ysVHx8vEJDQ7V161bl5ORoxowZmjVrVjM8ZQAAYDovdwYXFRVp6NChGjRokCSpe/fu+vTTT7Vt2zZJF87eZGdn680339QTTzwhSVq0aJGCg4O1dOlSjRo1Svv379eaNWtUXFysvn37SpI++ugjxcTE6MCBA4qIiNCSJUv03XffaeHChXI4HIqKitLBgwc1a9YsZWRkyMPDozk/BwAAwDBuBc7999+vefPm6eDBg7rzzjv1xRdfaPPmzcrOzpYkHT58WKWlpUpISLAf43A4FBcXp8LCQo0aNUpFRUUKDAy040aS7rvvPgUGBqqwsFAREREqKipSXFycHA6HPSYxMVGZmZk6cuSIwsPDG6yturpa1dXV9u3KykpJktPplNPpdOdpXlH9XM05JwD3sA9hGofnj+slGI42F9bbEnuwueZ0K3Bee+01VVRU6Kc//ak8PT1VW1urqVOn6tlnn5UklZaWSpKCg4NdHhccHKyjR4/aYzp37txg7s6dO9uPLy0tVffu3RvMUX/fpQInKytLkyZNanA8Pz9ffn5+7jzNRikoKGj2OQG4h30IU0zv09oraJqW2INnz55tlnncCpzly5dr8eLFWrp0qX72s59p586dGjdunEJDQ/Xcc8/Z475/CcmyLJdjl7rE9ENj6l9gfLnLU5mZmcrIyLBvV1ZWKiwsTAkJCQoICHDjWV6Z0+lUQUGB4uPj5e3t3WzzAmg89iFMEzUxr7WX4BZHG0vvRte1yB6svwJztdwKnF/96ld6/fXX9cwzz0iSevbsqaNHjyorK0vPPfecQkJCJF04y9KlSxf7cWVlZfYZmJCQEP3tb39rMPfXX3/tMqb+bM7Fc0gNzw7VczgcLpe06nl7e7fIF8CWmhdA47EPYYrq2h/na0tbYg8213xuvYvq7NmzatPG9SGenp7228TDw8MVEhLicsqqpqZGGzZsUGxsrCQpJiZGFRUV+vzzz+0xW7ZsUUVFhcuYjRs3qqamxh6Tn5+v0NDQBpeuAAAAvs+twBkyZIimTp2qVatW6ciRI8rNzdWsWbP0+OOPS7pw+WjcuHGaNm2acnNztWfPHqWkpMjPz0/Dhw+XJEVGRuqRRx5RamqqiouLVVxcrNTUVA0ePFgRERGSLryN3OFwKCUlRXv27FFubq6mTZvGO6gAAECjuHWJKicnR2+//bbGjBmjsrIyhYaGatSoUfr1r39tj5kwYYLOnTunMWPGqLy8XH379lV+fr78/f3tMUuWLFF6err9bqvHHntMc+bMse8PDAxUQUGB0tLSFB0draCgIGVkZLi8xgYAAOByPCxD/3ngyspKBQYGqqKiotlfZLx69WoNHDiQa/9AK2EfwjTdX1/V2ktwi8PT0vQ+tS2yB5vr+ze/iwoAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxnE7cP73f/9XI0aMUMeOHeXn56e7775bJSUl9v2WZWnixIkKDQ2Vr6+v+vfvr71797rMUV5eruTkZAUGBiowMFDJycn69ttvXcbs3r1bcXFx8vX1VdeuXTV58mRZltXEpwkAAG4kbgVOeXm5+vXrJ29vb/3lL3/Rvn37NHPmTHXo0MEeM336dM2aNUtz5szR1q1bFRISovj4eJ0+fdoeM3z4cO3cuVNr1qzRmjVrtHPnTiUnJ9v3V1ZWKj4+XqGhodq6datycnI0Y8YMzZo1qxmeMgAAMJ2XO4Pfe+89hYWFacGCBfax7t2723+2LEvZ2dl688039cQTT0iSFi1apODgYC1dulSjRo3S/v37tWbNGhUXF6tv376SpI8++kgxMTE6cOCAIiIitGTJEn333XdauHChHA6HoqKidPDgQc2aNUsZGRny8PBohqcOAABM5VbgrFy5UomJiXrqqae0YcMGde3aVWPGjFFqaqok6fDhwyotLVVCQoL9GIfDobi4OBUWFmrUqFEqKipSYGCgHTeSdN999ykwMFCFhYWKiIhQUVGR4uLi5HA47DGJiYnKzMzUkSNHFB4e3mBt1dXVqq6utm9XVlZKkpxOp5xOpztP84rq52rOOQG4h30I0zg8f1wvwXC0ubDeltiDzTWnW4HzP//zP5o7d64yMjL0xhtv6PPPP1d6erocDodGjhyp0tJSSVJwcLDL44KDg3X06FFJUmlpqTp37txg7s6dO9uPLy0tdTkzdPGcpaWllwycrKwsTZo0qcHx/Px8+fn5ufM0G6WgoKDZ5wTgHvYhTDG9T2uvoGlaYg+ePXu2WeZxK3Dq6uoUHR2tadOmSZLuuece7d27V3PnztXIkSPtcd+/hGRZlsuxS11i+qEx9S8wvtzlqczMTGVkZNi3KysrFRYWpoSEBAUEBDT2Kf4gp9OpgoICxcfHy9vbu9nmBdB47EOYJmpiXmsvwS2ONpbeja5rkT1YfwXmarkVOF26dFGPHj1cjkVGRmrFihWSpJCQEEkXzrJ06dLFHlNWVmafgQkJCdHf/va3BnN//fXXLmPqz+ZcPIfU8OxQPYfD4XJJq563t3eLfAFsqXkBNB77EKaorv1xvra0JfZgc83n1ruo+vXrpwMHDrgcO3jwoG699VZJUnh4uEJCQlxOWdXU1GjDhg2KjY2VJMXExKiiokKff/65PWbLli2qqKhwGbNx40bV1NTYY/Lz8xUaGtrg0hUAAMD3uRU4r7zyioqLizVt2jT993//t5YuXaoPP/xQaWlpki5cPho3bpymTZum3Nxc7dmzRykpKfLz89Pw4cMlXTjj88gjjyg1NVXFxcUqLi5WamqqBg8erIiICEkX3kbucDiUkpKiPXv2KDc3V9OmTeMdVAAAoFHcukTVu3dv5ebmKjMzU5MnT1Z4eLiys7OVlJRkj5kwYYLOnTunMWPGqLy8XH379lV+fr78/f3tMUuWLFF6err9bqvHHntMc+bMse8PDAxUQUGB0tLSFB0draCgIGVkZLi8xgYAAOBy3AocSRo8eLAGDx582fs9PDw0ceJETZw48bJjbrrpJi1evPiKH6dnz57auHGju8sDAADgd1EBAADzEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwDoEDAACMQ+AAAADjEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwDoEDAACMQ+AAAADjEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwDoEDAACMQ+AAAADjEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwDoEDAACMQ+AAAADjEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwDoEDAACMQ+AAAADjEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDhXFThZWVny8PDQuHHj7GPV1dUaO3asOnXqpHbt2umxxx7TX//6V5fHHTt2TEOGDFG7du3UqVMnpaenq6amxmXMhg0b1KtXL/n4+Oi2227TvHnzrmapAADgBtLkwNm6das+/PBD3XXXXS7Hx40bp9zcXC1btkybN29WVVWVBg8erNraWklSbW2tBg0apDNnzmjz5s1atmyZVqxYoVdffdWe4/Dhwxo4cKAeeOAB7dixQ2+88YbS09O1YsWKpi4XAADcQLya8qCqqiolJSXpo48+0pQpU+zjFRUVmj9/vj755BMNGDBAkrR48WKFhYVp7dq1SkxMVH5+vvbt26fjx48rNDRUkjRz5kylpKRo6tSpCggI0Lx589StWzdlZ2dLkiIjI7Vt2zbNmDFDTz755NU+ZwAAYLgmBU5aWpoGDRqkAQMGuAROSUmJnE6nEhIS7GOhoaGKiopSYWGhEhMTVVRUpKioKDtuJCkxMVHV1dUqKSnR3/3d36moqMhljvox8+fPl9PplLe3d4M1VVdXq7q62r5dWVkpSXI6nXI6nU15mpdUP1dzzgnAPexDmMbhabX2EtziaHNhvS2xB5trTrcDZ9myZdq+fbu2bt3a4L7S0lK1bdtWQUFBLseDg4NVWlpqjwkODna5PygoSG3btr3imODgYJ0/f14nT55Uly5dGnzsrKwsTZo0qcHx/Px8+fn5ufckG6GgoKDZ5wTgHvYhTDG9T2uvoGlaYg+ePXu2WeZxK3COHz+ul19+Wfn5+fLx8Wn04yzLkoeHh3374j83doxlWZd9rCRlZmYqIyPDvl1ZWamwsDAlJCQoICCg0Wv9IU6nUwUFBYqPj7/kmSQALY99CNNETcxr7SW4xdHG0rvRdS2yB+uvwFwttwKnpKREZWVl6tWrl32strZWGzdu1Jw5c5SXl6eamhqVl5e7nMUpKytTbGysJCkkJERbtmxxmbe8vFxOp9M+axMSEmKfzbl4Di8vL3Xs2PGSa3M4HHI4HA2Oe3t7t8gXwJaaF0DjsQ9hiuraS//wfr1riT3YXPO59S6qhx9+WLt379bOnTvt/6Kjo5WUlGT/2dvb2+WU1YkTJ7Rnzx47cGJiYrRnzx6dOHHCHpOfny+Hw2GHU0xMTIPTXvn5+fb8AAAAV+LWGRx/f39FRUW5HGvXrp06duxoH3/++ef16quvqmPHjrrppps0fvx49ezZ035XVUJCgnr06KHk5GT95je/0alTpzR+/Hilpqbal5JGjx6tOXPmKCMjQ6mpqSoqKtL8+fP16aefNsdzBgAAhmvSu6iuZPbs2fLy8tLTTz+tc+fO6eGHH9bChQvl6ekpSfL09NSqVas0ZswY9evXT76+vho+fLhmzJhhzxEeHq7Vq1frlVde0e9+9zuFhobq/fff5y3iAACgUa46cNavX+9y28fHRzk5OcrJybnsY7p166Y///nPV5w3Li5O27dvv9rlAQCAGxC/iwoAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHG8WnsBP1ZRE/NUXevR2stotCP/NKi1lwAAwDXDGRwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHG8WnsBANBUURPzVF3r0drLaLQj/zSotZcA3DA4gwMAAIxD4AAAAOMQOAAAwDgEDgAAMA6BAwAAjEPgAAAA4xA4AADAOAQOAAAwjluBk5WVpd69e8vf31+dO3fWsGHDdODAAZcx1dXVGjt2rDp16qR27drpscce01//+leXMceOHdOQIUPUrl07derUSenp6aqpqXEZs2HDBvXq1Us+Pj667bbbNG/evCY+RQAAcKNxK3A2bNigtLQ0FRcXq6CgQOfPn1dCQoLOnDljjxk3bpxyc3O1bNkybd68WVVVVRo8eLBqa2slSbW1tRo0aJDOnDmjzZs3a9myZVqxYoVeffVVe47Dhw9r4MCBeuCBB7Rjxw698cYbSk9P14oVK5rpaQMAAJO59asa1qxZ43J7wYIF6ty5s0pKSvTggw+qoqJC8+fP1yeffKIBAwZIkhYvXqywsDCtXbtWiYmJys/P1759+3T8+HGFhoZKkmbOnKmUlBRNnTpVAQEBmjdvnrp166bs7GxJUmRkpLZt26YZM2boySefbI7nDQAADHZVr8GpqKiQJN10002SpJKSEjmdTiUkJNhjQkNDFRUVpcLCQklSUVGRoqKi7LiRpMTERFVXV6ukpMQec/Ec9WO2bdsmp9N5NUsGAAA3gCb/sk3LspSRkaH7779fUVFRkqTS0lK1bdtWQUFBLmODg4NVWlpqjwkODna5PygoSG3btr3imODgYJ0/f14nT55Uly5dGqynurpa1dXV9u3KykpJktPpbNYoqp/L0cZqtjmvBcIQJmEfwjQOzx/X3+X6vdcSf6eba84mB85LL72kXbt2afPmzT841rIseXj8/2/8vfjPjR1jWdZlHytdeAH0pEmTGhzPz8+Xn5/fD67RXe9G1zX7nC1p9erVrb0EoNmxD2GK6X1aewVNU1BQ0Oxznj17tlnmaVLgjB07VitXrtTGjRt1yy232MdDQkJUU1Oj8vJyl7M4ZWVlio2Ntcds2bLFZb7y8nI5nU77rE1ISIh9NufiOby8vNSxY8dLrikzM1MZGRn27crKSoWFhSkhIUEBAQFNeZqX5HQ6VVBQoLe3tVF13aVj63q0Z2Jiay8BaDbsQ5gmamJeay/BLY42lt6NrlN8fLy8vb2bde76KzBXy63AsSxLY8eOVW5urtavX6/w8HCX+3v16iVvb28VFBTo6aefliSdOHFCe/bs0fTp0yVJMTExmjp1qk6cOGFfasrPz5fD4VCvXr3sMZ999pnL3Pn5+YqOjr7sJ9LhcMjhcDQ47u3t3eyffEmqrvNQde2P5wtrS3wOgNbGPoQpfkx/jy/WEt9jm2s+t15knJaWpsWLF2vp0qXy9/dXaWmpSktLde7cOUlSYGCgnn/+eb366qtat26dduzYoREjRqhnz572u6oSEhLUo0cPJScna8eOHVq3bp3Gjx+v1NRU+0zL6NGjdfToUWVkZGj//v36wx/+oPnz52v8+PHN8qQBAIDZ3AqcuXPnqqKiQv3791eXLl3s/5YvX26PmT17toYNG6ann35a/fr1k5+fnz777DN5enpKkjw9PbVq1Sr5+PioX79+evrppzVs2DDNmDHDniM8PFyrV6/W+vXrdffdd+vdd9/V+++/z1vEAQBAo7h9ieqH+Pj4KCcnRzk5OZcd061bN/35z3++4jxxcXHavn27O8sDAACQxO+iAgAABiJwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxCBwAAGAcAgcAABiHwAEAAMYhcAAAgHEIHAAAYBwCBwAAGIfAAQAAxiFwAACAcQgcAABgHAIHAAAYh8ABAADGIXAAAIBxruvA+eCDDxQeHi4fHx/16tVLmzZtau0lAQCAH4HrNnCWL1+ucePG6c0339SOHTv0wAMP6NFHH9WxY8dae2kAAOA6d90GzqxZs/T888/rhRdeUGRkpLKzsxUWFqa5c+e29tIAAMB1zqu1F3ApNTU1Kikp0euvv+5yPCEhQYWFhZd8THV1taqrq+3bFRUVkqRTp07J6XQ229qcTqfOnj0rL2cb1dZ5NNu8Le2bb75p7SUAzYZ9CNN4nT/T2ktwi1edpbNn6/TNN9/I29u7Wec+ffq0JMmyrKua57oMnJMnT6q2tlbBwcEux4ODg1VaWnrJx2RlZWnSpEkNjoeHh7fIGn9sOs1s7RUAYB/CJMNbeP7Tp08rMDCwyY+/LgOnnoeH609mlmU1OFYvMzNTGRkZ9u26ujqdOnVKHTt2vOxjmqKyslJhYWE6fvy4AgICmm1eAI3HPgRaV0vuQcuydPr0aYWGhl7VPNdl4HTq1Emenp4NztaUlZU1OKtTz+FwyOFwuBzr0KFDi60xICCAL6xAK2MfAq2rpfbg1Zy5qXddvsi4bdu26tWrlwoKClyOFxQUKDY2tpVWBQAAfiyuyzM4kpSRkaHk5GRFR0crJiZGH374oY4dO6bRo0e39tIAAMB17roNnF/+8pf65ptvNHnyZJ04cUJRUVFavXq1br311lZdl8Ph0DvvvNPgchiAa4d9CLSuH8Me9LCu9n1YAAAA15nr8jU4AAAAV4PAAQAAxiFwAACAcQic60j37t2VnZ3d2ssArlvr16+Xh4eHvv322yuOYy8B14+JEyfq7rvvvuYfl8C5Cv3799e4ceNaexnADSM2NlYnTpyw/xGwhQsXXvIf9Ny6datefPHFa7084Ibn4eGhP/3pTy7Hxo8fr3Xr1l3ztVy3bxM3hWVZqq2tlZcXn2rgarVt21YhISE/OO7mm2++BqsB0Bjt27dX+/btr/nHNfYMTv/+/ZWenq4JEybopptuUkhIiCZOnGjfX1FRoRdffFGdO3dWQECAHnroIX3xxRf2/SkpKRo2bJjLnOPGjVP//v3t+zds2KDf/va38vDwkIeHh44cOWKfQs/Ly1N0dLQcDoc2bdqkL7/8UkOHDlVwcLDat2+v3r17a+3atdfiUwFcU/3799dLL72kl156SR06dFDHjh311ltv2b8ZuLy8XCNHjlRQUJD8/Pz06KOP6tChQ/bjjx49qiFDhigoKEjt2rXTz372M61evVqS6yWq9evX6+///u9VUVFh78H6PX7xJapnn31WzzzzjMsanU6nOnXqpAULFki68IPI9OnTddttt8nX11c///nP9S//8i8t/akCms3Vfs+TpClTpqhz587y9/fXCy+8oNdff93l0tLWrVsVHx+vTp06KTAwUHFxcdq+fbt9f/fu3SVJjz/+uDw8POzbF1+iysvLk4+PT4PLzOnp6YqLi7NvFxYW6sEHH5Svr6/CwsKUnp6uM2fc+43rxgaOJC1atEjt2rXTli1bNH36dE2ePFkFBQWyLEuDBg1SaWmpVq9erZKSEt177716+OGHderUqUbN/dvf/lYxMTFKTU3ViRMndOLECYWFhdn3T5gwQVlZWdq/f7/uuusuVVVVaeDAgVq7dq127NihxMREDRkyRMeOHWuppw+0msNUrloAAAjgSURBVEWLFsnLy0tbtmzR+++/r9mzZ+v3v/+9pAs/HGzbtk0rV65UUVGRLMvSwIED5XQ6JUlpaWmqrq7Wxo0btXv3br333nuX/OkvNjZW2dnZCggIsPfg+PHjG4xLSkrSypUrVVVVZR/Ly8vTmTNn9OSTT0qS3nrrLS1YsEBz587V3r179corr2jEiBHasGFDS3x6gBZxNd/zlixZoqlTp+q9995TSUmJunXrprlz57rMf/r0aT333HPatGmTiouLdccdd2jgwIE6ffq0pAsBJEkLFizQiRMn7NsXGzBggDp06KAVK1bYx2pra/XHP/5RSUlJkqTdu3crMTFRTzzxhHbt2qXly5dr8+bNeumll9z7hFiGiouLs+6//36XY71797Zee+01a926dVZAQID13Xffudz/k5/8xPrnf/5ny7Is67nnnrOGDh3qcv/LL79sxcXFuXyMl19+2WXMf/zHf1iSrD/96U8/uMYePXpYOTk59u1bb73Vmj17dqOeH3C9iouLsyIjI626ujr72GuvvWZFRkZaBw8etCRZ//mf/2nfd/LkScvX19f64x//aFmWZfXs2dOaOHHiJeeu31/l5eWWZVnWggULrMDAwAbjLt5LNTU1VqdOnayPP/7Yvv/ZZ5+1nnrqKcuyLKuqqsry8fGxCgsLXeZ4/vnnrWeffbYpnwLgmrva73l9+/a10tLSXO7v16+f9fOf//yyH/P8+fOWv7+/9dlnn9nHJFm5ubku49555x2XedLT062HHnrIvp2Xl2e1bdvWOnXqlGVZlpWcnGy9+OKLLnNs2rTJatOmjXXu3LnLruf7jD6Dc9ddd7nc7tKli8rKylRSUqKqqip17NjRvjbYvn17HT58WF9++WWzfOzo6GiX22fOnNGECRPUo0cPdejQQe3bt9d//dd/cQYHRrrvvvvk4eFh346JidGhQ4e0b98+eXl5qW/fvvZ9HTt2VEREhPbv3y/pwqnqKVOmqF+/fnrnnXe0a9euq1qLt7e3nnrqKS1ZskTShb34b//2b/ZPi/v27dN3332n+Ph4l68HH3/8cbN9PQCuhav5nnfgwAH16dPH5fHfv11WVqbRo0frzjvvVGBgoAIDA1VVVeX297GkpCStX79eX331laQLZ48GDhyooKAgSVJJSYkWLlzostbExETV1dXp8OHDjf44Rr/y1dvb2+W2h4eH6urqVFdXpy5dumj9+vUNHlP/jow2bdrYrxmoV38KvTHatWvncvtXv/qV8vLyNGPGDN1+++3y9fXVL37xC9XU1DR6TsBUlmXZQfTCCy8oMTFRq1atUn5+vrKysjRz5kyNHTu2yfMnJSUpLi5OZWVlKigokI+Pjx599FFJUl1dnSRp1apV6tq1q8vjruffswN839V8z6sff7Hvfw9MSUnR119/rezsbN16661yOByKiYlx+/tYnz599JOf/ETLli3TP/7jPyo3N9d+PZx0YU+OGjVK6enpDR7brVu3Rn8cowPncu69916VlpbKy8vLfhHU9918883as2ePy7GdO3e6/AVq27atamtrG/UxN23apJSUFD3++OOSpKqqKh05cqRJ6weud8XFxQ1u33HHHerRo4fOnz+vLVu2KDY2VpL0zTff6ODBg4qMjLTHh4WFafTo0Ro9erQyMzP10UcfXTJwGrsHY2NjFRYWpuXLl+svf/mLnnrqKbVt21aS1KNHDzkcDh07dszlRY6AKRrzPS8iIkKff/65kpOT7WPbtm1zGbNp0yZ98MEHGjhwoCTp+PHjOnnypMsYb2/vRu3J4cOHa8mSJbrlllvUpk0bDRo0yGW9e/fu1e23397Yp3hJRl+iupwBAwYoJiZGw4YNU15eno4cOaLCwkK99dZb9v/Qhx56SNu2bdPHH3+sQ4cO6Z133mkQPN27d9eWLVt05MgRnTx50v5J8FJuv/12/eu//qt27typL774QsOHD7/ieODH7Pjx48rIyNCBAwf06aefKicnRy+//LLuuOMODR06VKmpqdq8ebO++OILjRgxQl27dtXQoUMlXXi3Yl5eng4fPqzt27fr3//9313i52Ldu3dXVVWV1q1bp5MnT+rs2bOXHOfh4aHhw4dr3rx5Kigo0IgRI+z7/P39NX78eL3yyitatGiRvvzyS+3YsUO/+93vtGjRoub/5ADXWGO+540dO1bz58/XokWLdOjQIU2ZMkW7du1yOatz++2365NPPtH+/fu1ZcsWJSUlydfX1+Vjde/eXevWrVNpaanKy8svu6akpCRt375dU6dO1S9+8Qv5+PjY97322msqKipSWlqadu7cqUOHDmnlypVun8W9IQPHw8NDq1ev1oMPPqh/+Id/0J133qlnnnlGR44cUXBwsCQpMTFRb7/9tiZMmKDevXvr9OnTGjlypMs848ePl6enp3r06KGbb775itchZ8+eraCgIMXGxmrIkCFKTEzUvffe26LPE2gtI0eO1Llz59SnTx+lpaVp7Nix9j+8t2DBAvXq1UuDBw9WTEyMLMvS6tWr7bOjtbW1SktLU2RkpB555BFFRETogw8+uOTHiY2N1ejRo/XLX/5SN998s6ZPn37ZNSUlJWnfvn3q2rWr+vXr53Lfu+++q1//+tfKyspSZGSkEhMT9dlnnyk8PLyZPiNA62nM97ykpCRlZmZq/Pjxuvfee3X48GGlpKS4hMcf/vAHlZeX65577lFycrLS09PVuXNnl481c+ZMFRQUKCwsTPfcc89l13THHXeod+/e2rVrl/16uHp33XWXNmzYoEOHDumBBx7QPffco7fffltdunRx73lb37/IBgBXoX///rr77rv5VQnAj1x8fLxCQkL0ySeftPZSmuSGfA0OAAD4f2fPntW8efOUmJgoT09Pffrpp1q7dq0KCgpae2lNRuAAAHCDq7+MNWXKFFVXVysiIkIrVqzQgAEDWntpTcYlKgAAYJwb8kXGAADAbAQOAAAwDoEDAACMQ+AAAADjEDgAAMA4BA4AADAOgQMAAIxD4AAAAOMQOAAAwDj/BxUk8kS39vN7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_['airline_sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7cb341f-5691-4b9f-ae3e-2880288add0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_map = {'positive':1.0, 'negative':0.0, 'neutral':2.0}\n",
    "df_['target'] = df_.airline_sentiment.map(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b68eeeb-78f6-46f1-b8a6-95373d491e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  target\n",
       "0           neutral                @VirginAmerica What @dhepburn said.     2.0\n",
       "1          positive  @VirginAmerica plus you've added commercials t...     1.0\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...     2.0\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...     0.0\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...     0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e542040f-e59f-4aae-bb3a-f2f9a6dfb7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df_[['text','target']]\n",
    "df2.columns = ['sentence','labels']\n",
    "df2.to_csv('data_interm_sent.csv', index =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6d305dc-5606-412b-bdae-f7457927b6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence,labels\n",
      "@VirginAmerica What @dhepburn said.,2.0\n",
      "@VirginAmerica plus you've added commercials to the experience... tacky.,1.0\n",
      "@VirginAmerica I didn't today... Must mean I need to take another trip!,2.0\n",
      "\"@VirginAmerica it's really aggressive to blast obnoxious \"\"entertainment\"\" in your guests' faces &amp; they have little recourse\",0.0\n",
      "@VirginAmerica and it's a really big bad thing about it,0.0\n",
      "\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA\",0.0\n",
      "\"@VirginAmerica yes, nearly every time I fly VX this “ear worm” won’t go away :)\",1.0\n",
      "\"@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP\",2.0\n"
     ]
    }
   ],
   "source": [
    "!head data_interm_sent.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbdc4ba0-31e4-42b2-8cc8-30e818ac2357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3aad05d-f6fe-4e52-8d2e-febc5109cb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-96a8a5a5e66f0e40/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c2ce72aac3452abb1bb2d03e9f48cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1841083b2e754a94a73af7b5e20706b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-96a8a5a5e66f0e40/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aceab69e780e4de694f19f64b91c15c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dataset = load_dataset('csv', data_files ='data_interm_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1841b97a-22b6-4bae-8f4f-9e11af396aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'labels'],\n",
       "        num_rows: 14640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "866c860d-7666-4a69-9fbf-e7a7034e6ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = raw_dataset['train'].train_test_split(test_size=0.3, seed =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfe1c224-c6a1-421f-9f92-38fe20f5ef35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'labels'],\n",
       "        num_rows: 10248\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'labels'],\n",
       "        num_rows: 4392\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bafbf2b2-7111-4ff6-b6c1-24fe02074347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef3b4e33-58b7-4ceb-9552-2539e4f3bb73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0be97826cf496796ac49416856502b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a0e26275e348049da31682716dc448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034377961b2440eb8c38fbc0e083041d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326df52e31574ccba59cfd8544fc1505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d6012ac-f814-460a-b23a-4e15a018105b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60c25271-27de-44ec-9d34-f78b24c2ec1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = split.map(tokenize_fn, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59d8c6fa-f8a8-413a-b636-2f2a6bd66e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90df97baf774288a0116f6b542b2746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a809d5d-e6a1-4c2a-96e8-119aada368ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "DistilBertForSequenceClassification                     --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              22,268,928\n",
       "│    │    └─Embedding: 3-2                              393,216\n",
       "│    │    └─LayerNorm: 3-3                              1,536\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             42,527,232\n",
       "├─Linear: 1-2                                           590,592\n",
       "├─Linear: 1-3                                           2,307\n",
       "├─Dropout: 1-4                                          --\n",
       "================================================================================\n",
       "Total params: 65,783,811\n",
       "Trainable params: 65,783,811\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5647271-5f54-4fe1-ac7a-9a8a90f73e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='training_dir',\n",
    "    evaluation_strategy ='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47bd4602-175a-4980-8571-1f27aa2f52cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = np.mean(prediccions == labels)\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return {'accuracy':acc, 'f1':f1}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98c94717-4d6e-4915-a75e-e7d3298d8661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model,\n",
    "                  training_args,\n",
    "                  train_dataset=tokenized_ds[\"train\"],\n",
    "                  eval_dataset=tokenized_ds[\"test\"],\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b95ecd-25fa-4034-8e75-95f795f7ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496e1d0-a693-4f9d-9708-0783d3989331",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel = pipeline('text-classification',\n",
    "                      model = 'training-dir/checkpoint-1282')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc362276-3d0b-46a9-a561-870679482761",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = savedmodel(split['test']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0491d9-b9bc-4adf-9318-d5190300a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3bd53-6e28-4c13-8a43-b23e7a62607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2683e-cd8f-4af5-8c35-8ffdd7550701",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292fd9b-174f-488e-a3b7-f12949635d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ba078-affc-4e17-836c-c5d50c9d2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.id2label = {v:k for k,v in target_map.items()}\n",
    "config.label2id = target_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee5e74-1f32-4274-93f6-20823eb8be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from-pretrained(\n",
    "    checkpoint, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14916f-30b6-44b9-b920-cdda18f3fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8567c0-f518-49ba-8bec-51dcf7230b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92926b2-77b6-452d-a5ff-ce61ce87cd54",
   "metadata": {},
   "source": [
    "#  Excercise 1\n",
    "#### Evaluate with two classes original vs fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d2b02-3a42-49e3-9455-084091399b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bcda354-f11c-4f78-a1be-aa41f50a7d6c",
   "metadata": {},
   "source": [
    "# Fine Tuning Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed9c66f9-fd2f-4b60-b653-64c8ed5da097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/rte to /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3668f8ceca4df487ac6558b97f17b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/697k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdc066584d64b1f9d4bc7832852991a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"rte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f8c8842-7592-4548-8d21-15eca05fb29a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 277\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6351ee3a-6923-4a77-849a-604dd9e553a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['entailment', 'not_entailment'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2282d652-0617-4b99-971a-a62b2876cd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No Weapons of Mass Destruction Found in Iraq Yet.',\n",
       " 'A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI.',\n",
       " 'Herceptin was already approved to treat the sickest breast cancer patients, and the company said, Monday, it will discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.',\n",
       " 'Judie Vivian, chief executive at ProMedica, a medical service company that helps sustain the 2-year-old Vietnam Heart Institute in Ho Chi Minh City (formerly Saigon), said that so far about 1,500 children have received treatment.',\n",
       " \"A man is due in court later charged with the murder 26 years ago of a teenager whose case was the first to be featured on BBC One's Crimewatch. Colette Aram, 16, was walking to her boyfriend's house in Keyworth, Nottinghamshire, on 30 October 1983 when she disappeared. Her body was later found in a field close to her home. Paul Stewart Hutchinson, 50, has been charged with murder and is due before Nottingham magistrates later.\",\n",
       " 'Britain said, Friday, that it has barred cleric, Omar Bakri, from returning to the country from Lebanon, where he was released by police after being detained for 24 hours.',\n",
       " \"Nearly 4 million children who have at least one parent who entered the U.S. illegally were born in the United States and are U.S. citizens as a result, according to the study conducted by the Pew Hispanic Center. That's about three quarters of the estimated 5.5 million children of illegal immigrants inside the United States, according to the study. About 1.8 million children of undocumented immigrants live in poverty, the study found.\",\n",
       " 'Like the United States, U.N. officials are also dismayed that Aristide killed a conference called by Prime Minister Robert Malval in Port-au-Prince in hopes of bringing all the feuding parties together.',\n",
       " \"WASHINGTON --  A newly declassified narrative of the Bush administration's advice to the CIA on harsh interrogations shows that the small group of Justice Department lawyers who wrote memos authorizing controversial interrogation techniques were operating not on their own but with direction from top administration officials, including then-Vice President Dick Cheney and national security adviser Condoleezza Rice. At the same time, the narrative suggests that then-Defense Secretary Donald H. Rumsfeld and then-Secretary of State Colin Powell were largely left out of the decision-making process.\",\n",
       " 'Only a week after it had no comment on upping the storage capacity of its Hotmail e-mail service, Microsoft early Thursday announced it was boosting the allowance to 250MB to follow similar moves by rivals such as Google, Yahoo, and Lycos.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['sentence1'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61ccf9cf-31e5-48b6-ba76-fc868b982d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6acc3d61-7d24-4fd2-bdba-7eaae9276076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb52ffc0-2aef-4149-9d84-cd7440a0ab86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "446ca486-d2e0-4566-ad6f-c209ee3997a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1302, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 6355, 119, 102, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(raw_datasets['train']['sentence1'][0],\n",
    "          raw_datasets['train']['sentence2'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec44a17d-b380-4313-8e16-a36c0b82bb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "176895ca-8327-4a0a-a35b-4532adbd6e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30d84b08-d586-4594-9927-07b85bb30d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] No Weapons of Mass Destruction Found in Iraq Yet. [SEP] Weapons of Mass Destruction Found in Iraq. [SEP]'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(result['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b79ec1b-cf28-423c-9239-88ba7009d816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41060956-17bf-47d8-8c8f-b118ab75bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'training_dir',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy ='epoch',\n",
    "    num_train_epochs =1,\n",
    "    per_device_train_batch_size =16,\n",
    "    per_device_eval_batch_size = 64,\n",
    "    logging_steps = 150)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
